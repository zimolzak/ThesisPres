Thanks everyone for coming and for staying for the last presentation
of the day. Up front I would just like to thank my committee members
for their helpful comments through the course of putting this
together. My formal title is "Medication Adherence: how should we
measure it, and can we detect it early?" 

If you'd like a definition, adherence is the extent to which patients
take medications as prescribed. First I will talk about five simple
facts about adherence that took me a while to realize, and then I will
discuss my research about early detection. 

THE FIRST FACT IS: ADHERENCE IS GOOD.

Poor adherence has been associated with increased mortality. It is
associated with disease progression in clinical trials, and with
increased disease-related hospitalizations in real-world populations.
About half of adverse drug event-related hospitalizations are
attributable to poor adherence, and those hospitalizations cause
increased costs. All of this has been described in a number of
studies. A 2009 study from the NEHI estimated 289 billion annually in
what they call drug-related morbidity in the US. That covers
nonadherence, but also problems with prescribing, administration, and
diagnosis.

Finally, in 2012, CMS tied adherence to 3 particular classes of
medications to payment. Payment is actually based on 15-20 different
quality measures, but three of theme are specifically adherence, and
they're based on prescription fills. So even if you don't believe
anything about worse outcomes or costs, if you're a Medicare plan
manager, believe that adherence is good because it can make you more
money. This CMS definition informed how we operationalized the
definition of adherence.

THE SECOND FACT IS: Nonadherence is common.

These are two studies of people who just initiated statins. By 6
months, half have stopped taking statins. This upper curve is for
secondary prevention (if you've just had a heart attack). Your
adherence is better, but not by much.

THIRD FACT: There is No gold standard measure of adherence.

I already mentioned prescription fills as a measure of adherence. A
second measure would be pill counts. In a trial, each subject might
come periodically with any unused pills, to determine how many he or
she took. Third, you could ask patients to keep a diary or
retrospectively think back about how often they took the medication.
Fourth, sometimes you can measure drug levls in blood commercially, or
by research assay. Fifth, you can have [**picture] an electronic
device that records each time you open a pill bottle.

Each of these measures has its own pros and cons. Actually, each is
giving you different information; none of them is considered the gold
standard. In our study, we use prescription fills, per the CMS
definition.

In one chapter of my thesis, which I can't discuss fully, I reviewed
the literature to count how many studies correlate one measure to
another. The width of each edge shows the value of that count, and
brighter colors mean stronger correlation. I would argue that this
figure shows that at least fills are well studied. Just know that they
are not the only way to measure adherence.

FOURTH FACT: adherence Interventions work but can be complex.

There are many trials of adherence interventions, but many are
complex. In one study, an intervention pharmacist was trained by
several other pharmacists, a cardiologist, a geriatrician, a
behavioral scientist, and a cognitive psychologist, and this
well-trained person then delivered an intervention to patients over 9
months, using a tailored protocol. After the intervention period, the
positive effects dissipated in 3 months. One systematic review
concludes, "many of the adherence interventions for long-term
medications were exceedingly complex and labor-intensive. It is
therefore difficult to see how they could be carried out in
non-research settings."

Not everything is complex, though, like this recent trial in the New
England Journal. Here, reduced copayment improved adherence by 4-6
percentage points. There was no significant difference in the primary
outcome, and small differences in secondary outcomes. Reducing
copayment is maybe not so complex as training a small army of
multidisciplinary teams. So not all interventions are exceedingly
complex, but many are.

In any case, this is why we want to predict adherence: to target
expensive interventions to people at highest risk for poor adherence.

FIFTH FACT: Some predictors of adherence don't work so well.

Here's an example of a study that tries to predict statin adherence
from 19 features of the patient, physician, and drug payment levels.
The full model had an area under the curve of 0.63, which means it
didn't work so well. Several papers have stated that we probably can't
predict adherence from someone's appearance, problem list, or
physician or payment characteristics. To quote one review, "adherence
must be measured, not inferred." However, a previous study out of the
lab where I'm working showed good model performance by using past
adherence to predict future adherence. But this paper didn't compare
the early detection feature to many other potential features, and it
also selected a cohort who tended to relatively high mean adherence:
higher than that what we expect in the general population.

This sets up my research, which is meant to build an early detection
model, but do 2 additional things. First, compare the early detection
strategy to the traditional strategy. Second, use the CMS definition
so the model becomes relevant to pay-for-performance.

[stop for questions.]
[original: 13m, 85wpm]
[current : 10.4m, 884w]
[target  : 10m, 850w, 100L]

METHODS

Our data source was prescription claims from Aetna, on about 600,000
commercial members, who met criteria for hyperlipidemia.

The major predictor we're interested in is adherence for the first 90
days. That's going into the model as a continuous variable. Sometimes
I'll call them predictors or features. We defined the dependent
variable the same way CMS did. CMS defines this as a binary condition,
specifically whether something called the Proportion of Days Covered
is greater or less than 80%.

We then calculated 15 other features including number of non-statin
pills, copayment amounts, features that describe how people obtain
their statins, and whether someone had a heart attack in the 30 days
before statin initiation.

We worked hard to separate them so we're not using anything beyond the
initial 90 days as a predictor or exclusion.

We excluded anyone who we don't think is really starting the statin
brand new because of those curves I showed you--because they behave
differently--at the beginning there's a big drop. Then there are some
less common exclusion criteria. We're left with 210,000 people, who we
split randomly into a 140,000 person training set and a 70,000 person
test set. We trained logistic regression on the training set and
scored on the test set.

[original: 17m, 7.7Lpm, 79wpm]
[current : 16.5m, 1300w]

RESULTS

In our included cohort, the median age is 54. The cohort is 45% women.
58% are on simvastatin, followed by rosuvastatin and atorvastatin, and
only 2% is on something else. For the early monitoring period, first
quartile is 0.59, and 3rd quartile is 1.0. For the dependent variable,
46% are classed as poor adherers, 24% as good, and 30% actually left
the insurance plan so we couldn't determine poor or good. They're on a
median of 0.4 pills per day, 3rd quartile 1.8 pills per day. There's
only 2% with MI in the last 30 days.

When we looked at bivariate pairwise associations, the big one that
stands out is the early monitoring period. The odds ratio is 19.7. The
next biggest ones after that are between 2 and 3 (mail order is good,
no ACS is bad). The interpretation is if you're the people
with early adherence down by 0.5, then your odds of low adherence in
the later time frame is multiplied by 20. So it's in the intuitive
direction: you do worse at the beginning, and you do worse at the end.

Now for the multivariable model. This is the ROC curve, and the area
under the curve is 0.8, so that tells us we have a good model. When
the study was published with the 0.63 AUC, an accompanying editorial
said that you can't make any accurate predictions from demographic and
comorbidity data, and there's probably no signal in them. I would
agree with that. But if you use this early monitoring period, it is
acting as a proxy for a lot of these personal characteristics that we
can't get from claims, like who's working two jobs or whose work
schedule is weird & they have to get up at different hours & no
standard routine. From smaller studies, we think these personal
characteristics are a big influence on adherence.

[original: 23m, 7.3Lpm, 74wpm]
[current : 22m, 1623w]

Here are the odds ratios of the multivariable model. Things that are
worse for your adherence are on the right side of this graph. The
worst thing is if you have low adherence in the early monitoring
period. This is a log scale. This odds ratio is 25. The next worst one
is 2.4. The point is not so much the other covariates, but how far the
early detection feature stands out. One review article makes the
argument that an odds ratio of 2 is still not very good for predicting
adherence.

Finally, this is the really interesting part. The 90 day early
detection period made clinical sense, but maybe we can make it
shorter, or maybe we ought to make it longer. So, we plotted model
performance on the Y axis versus length of the early monitoring period
on the X axis. The top curve is the cohort who get 30 day fills of
medications. You'll see that if you have between 0 to 30 days of
monitoring data, you get a weak model, with an AUC around 0.6, not far
from the study I showed you. If you wait to get 31 days of data, you
get a big increase, and if you wait til 40 you get a further increase.
You then start to level off and increase more slowly, for as long as
you're willing to wait. The point is a tradeoff between two qualities.
You can have an early but less accurate prediction, or you can have a
later but more accurate one. You see a similar pattern for those who
get the 90 day fills. They get a big increase in model performance
between 90 and 100 days. In summary, the timing of the first refill
plays a big part in the discriminatory power of this model.

[**table from poster]

DISCUSSION

Who would use this? One is insurance plan manager. If people fill
these meds on time, Medicare plan might increase star rating, and then
get an increased bonus payment. Two is if you're a clinic or an ACO,
you want your people to have fewer complications. You want to get your
hands on fill data, so when someone starts on a new med you can watch
the first refill point, and if they don't within 10 days, you'll want
to intervene.

Now I want to discuss opportunities for future research. At the
beginning, I showed you that there's other ways to measure adherence
apart from fills. Prescription claims are not the same as
quote-unquote true adherence. With a claim, I know they filled 30
pills, but then I don't know what they're doing day to day, until the
next claim comes along. There's no gold standard, and incorporating
one of these other measures would add a lot of information.

Secondly, it is for the most part arbitrary to define good adherence
as Proportion of Days Covered equal or greater to 80%. There's
virtually no research I know of that uses clinical outcomes to
determine where to draw the line on how much you need to take your
medicines. Even those secondary analyses of clinical trial data that I
told you about in the beginning: even they said, let's compare the
over-80% to the under-80% group. At least CMS has artificially made
80% worthwhile by tying some reimbursement it. That's what we're using
in our study, but we haven't yet used any outcome data. There is an
opportunity to incorporate outcomes, such as hospitalization, or even a
surrogate like labs.

Third, we're just looking at statins. There is an opportunity to
expand to other drug classes.

Fourth, we're looking just at statin adherence predicts statin
adherence. What does blood pressure medicine adherence have to say
about statin adherence, or vice versa? You can come up with many of
these possible relationships. Some chronic medications might have
bearing on others; some might not; or only in certain situations. It
turns into a pretty interesting problem.

To sum up, demographic and payment characteristics are not good
predictors of adherence. But those are not the extent of the
information encompassed by claims data. there is valuable signal to be
found in claims data, and people's prior adherence history is one such
signal that can predict future adherence.

[original: 32.5m, 7.16Lpm, 73wpm.]
[current : 2360w, 32.3m]
[target  : 1460-1600w, 20m]

[bring bottle of water!! poss kleenex. Put on the side: my paper, my
definition. steiner paper.]





 LocalWords:  Horwitz NEHI operationalized uber multipage think's LPM meds AUC
 LocalWords:  steiner AUCs tradeoff kleenex WalMart Aetna thru hyperlipidemia
 LocalWords:  Lpm adherers
