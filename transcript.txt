Thanks everyone for coming and for staying for the last presentation
of the day. Up front I would just like to thank my committee members
for their helpful comments through the course of putting this
together. My formal title is "Medication Adherence: how should we
measure it, and can we detect it early?" I will focus mainly on the
early detection.

** going to tell you some nuances that I learned about adherence, and
   about my research.

** go thru and find all asterisks.

DEFINITION

But first, some background about medication adherence. I'll use this
definition: "The extent to which patients take medications as
prescribed by their health care providers." Why would you be
interested in such a thing? Who says adherence is good in the first
place?

OUTCOMES

Well, because first of all, poor adherence has been associated with
increased mortality (Horwitz). [**mention healthy adherer] Second,
poor adherence is associated with disease progression in clinical
trials, and with increased disease-related hospitalizations in
real-world populations. Between 30 and 70 % of adverse drug
event-related hospitalizations are attributable to poor adherence.
Furthermore, literature shows that a lot of the increased costs are
due to hospitalizations. So we think that you don't take the medicine,
you get an exacerbation or complication of chronic disease, and you
have a stay in the hospital. It might not even be a bad exacerbation,
but that results in increased costs for you and for the system, and in
indirect costs, such as the things you could be doing while you're not
in the hospital.

COST

A 2009 study from the NEHI estimated 289 billion in what they call
drug-related morbidity in the US. That covers how medications are used
in the ambulatory setting only and it includes adherence problems, as
well as problems with prescribing, administration, and diagnosis,
which result in adverse drug events, interactions, etc.

BONUS

Finally, not too long ago, CMS tied adherence to 3 particular classes
of medications to payment, and one of those classes is the statins.
That informed how we operationalized the definition of adherence.
Payment is actually based on 15-20 different quality measures, but
three of theme are specifically adherence, and they're based on
prescription fills. So even if you don't believe anything about worse
outcomes or costs, if you're a Medicare plan manager, believe that
you're going to make more money if your members are more adherent.

PREVALENT

We know nonadherence is bad. How prevalent is it? It's pretty
prevalent. These are two studies of people who just initiated statins
which show that by 6 months, half of the people have stopped taking
statins. This upper curve is for secondary prevention (if you've just
had a heart attack). You're more likely to continue than are the
people who were just told they have high cholesterol, but it's still
only 50-60% at 6 to 12 months. So stopping medications is a common
occurrence.

MEASURES

Now that we know adherence is important, how do we measure it? There
are several ways, and I already mentioned that Medicare's uses
prescription fills. Second, there are also pill counts. In a trial,
each subject might come back at the end of every month with any unused
pills, to determine how many he or she took. Third, you could ask
patients to keep a diary or retrospectively think back--globally or
quantitatively--how often did you miss, or how well did you do?
Fourth, with some drugs you can order a blood level commercially, or
you can have a specialized research assay that measures levels. Fifth,
you can have [**picture] a device that records each time you open a
bottle. 

Each of these measures has its own pros, cons, and ways they can give
you inaccurate data. there's none that's considered the gold standard.
We use prescription fills. 

For one part of my thesis, which I don't have time to discuss fully, I
reviewed the literature to count how many studies correlate one
measure to another. I would argue that this figure shows that fills
are well studied. They have good correlation with other measures. Just
know that this is not the only way to measure adherence. 

INTERVENTION

Now that we know how to measure adherence, how can we improve it?
There are many trials of adherence interventions, but many are
complex. In one study, for example, an intervention pharmacist was
trained by several other pharmacists, a cardiologist, a geriatrician,
a behavioral scientist, and a cognitive psychologist, and he
intervened over a 9 month period, with effects that dissipated in 3
months (Murray et al., 2007). One systematic review concluded that
"many of the adherence interventions for long-term medications were
exceedingly complex and labor-intensive. It is therefore difficult to
see how they could be carried out in non-research settings" (Haynes et
al., 2008). I think when they say that, they forget about one thing
that's simple to do, which is reduce copayment. There was a trial of
that a year and a half ago in the New England Journal, and they found
it improved adherence by 4-6 percentage points, but there was no
significant difference in the incidence rate of the primary outcome,
and small significant differences in the incidence rate of secondary
outcomes. This was an important trial, and it's worth pointing out
that you can do that to a lot of people. There's no logistic problem
with doing that for 10 vs 100 vs 1000. It's not the same as the
pharmacist contacting a thousand people. The point is, we're trying to
do this prediction to target those complex interventions to the people
at highest risk for poor adherence. 

PREVIOUS MODELS

Now that we know why, here's an example of a study that tries to
predict statin adherence from 19 features of the patient, physician,
and drug copayment. The full model had an area under the curve of
0.63. So it didn't work so well. By contrast, a previous study out of
the lab where I'm working showed good model performance by using past
adherence to predict future adherence. However, this study didn't
compare the early detection feature to many other potential features,
and it also selected a cohort who tended to relatively high mean
adherence: higher than that what we expect in the general population.

[stop for questions.]
[original: 13m, 85wpm]
[current : 12m]
[target  : 10m, 850w, 100L]

METHODS

Now I'm going to discuss the original research that resulted in the
main findings of my thesis. The goal was to build an early detection
model, but one that compares the early detection strategy to the
traditional strategy of using patient and drug data at the time of
prescribing to predict drug adherence. Our data source was
prescription claims from Aetna, on about 600,000 commercial members,
who met criteria for hyperlipidemia.

The major predictor we're interested in is adherence for the first 90
days. That's going into the model as a continuous variable. Sometimes
I'll call them predictors or features. We defined the dependent
variable the same way CMS did. CMS defines this as a binary condition,
specifically whether something called the Proportion of Days Covered
is greater or less than 80%.

We then calculated 15 other features including number of non-statin
pills, copayment amounts, features that describe how people obtain
their statins, and whether someone had a heart attack in the 30 days
before statin initiation.

We worked hard to separate them so we're not using anything beyond the
initial 90 days as a predictor or exclusion [**maybe reword].

We excluded anyone who we don't think is really starting the statin
brand new because of those curves I showed you--because they behave
differently--at the beginning there's a big drop. Then there are some
less common exclusion criteria. We're left with 210,000 people, who we
split randomly into a 140,000 person training set and a 70,000 person
test set. We trained logistic regression on the training set and
scored on the test set.

[original: 17m, 7.7Lpm, 79wpm]
[current : 16.5m, 1300w]
[target  : ]

RESULTS

In our included cohort, the median age is 54. The cohort is 45% women.
58% are on simvastatin, followed by rosuvastatin and atorvastatin, and
only 2% is on something else. For the early monitoring period, first
quartile is 0.59, and 3rd quartile is 1.0. For the dependent variable,
46% are classed as poor adherers, 24% as good, and 30% actually left
the insurance plan so we couldn't determine poor or good. They're on a
median of 0.4 pills per day, 3rd quartile 1.8 pills per day. There's
only 2% with MI in the last 30 days.

When we looked at bivariate pairwise associations, the big one that
stands out is the early monitoring period. The odds ratio is 19.7. The
next biggest ones after that are between 2 and 3 (mail order is good,
no ACS is bad). The interpretation is if you're the people
with early adherence down by 0.5, then your odds of low adherence in
the later time frame is multiplied by 20. So it's in the intuitive
direction: you do worse at the beginning, and you do worse at the end.

Now for the multivariable model. This is the ROC curve, and the area
under the curve is 0.8, so that tells us we have a good model. When
the study was published with the 0.63 AUC, an accompanying editorial
said that you can't make any accurate predictions from demographic and
comorbidity data, and there's probably no signal in them. I would
agree with that. But if you use this early monitoring period, it is
acting as a proxy for a lot of these personal characteristics that we
can't get from claims, like who's working two jobs or whose work
schedule is weird & they have to get up at different hours & no
standard routine. From smaller studies, we think these personal
characteristics are a big influence on adherence.

[original: 23m, 7.3Lpm, 74wpm]
[current : 22m, 1623w]

Here are the odds ratios of the multivariable model. Things that are
worse for your adherence are on the right side of this graph. The
worst thing is if you have low adherence in the early monitoring
period. This is a log scale. This odds ratio is 25. The next worst one
is 2.4. The point is not so much the other covariates, but how far the
early detection feature stands out. One review article makes the
argument that an odds ratio of 2 is still not very good for predicting
adherence.

Finally, this is the really interesting part. The 90 day early
detection period made clinical sense, but maybe we can make it
shorter, or maybe we ought to make it longer. So, we plotted model
performance on the Y axis versus length of the early monitoring period
on the X axis. The top curve is the cohort who get 30 day fills of
medications. You'll see that if you have between 0 to 30 days of
monitoring data, you get a weak model, with an AUC around 0.6, not far
from the study I showed you. If you wait to get 31 days of data, you
get a big increase, and if you wait til 40 you get a further increase.
You then start to level off and increase more slowly, for as long as
you're willing to wait. The point is a tradeoff between two qualities.
You can have an early but less accurate prediction, or you can have a
later but more accurate one. You see a similar pattern for those who
get the 90 day fills. They get a big increase in model performance
between 90 and 100 days. In summary, the timing of the first refill
plays a big part in the discriminatory power of this model.

[**table from poster]

DISCUSSION

Who would use this? One is insurance plan manager. If people fill
these meds on time, Medicare plan might increase star rating, and then
get an increased bonus payment. Two is if you're a clinic or an ACO,
you want your people to have fewer complications. You want to get your
hands on fill data, so when someone starts on a new med you can watch
the first refill point, and if they don't within 10 days, you'll want
to intervene.

Now I want to discuss opportunities for future research. At the
beginning, I showed you that there's other ways to measure adherence
apart from fills. Prescription claims are not the same as
quote-unquote true adherence. With a claim, I know they filled 30
pills, but then I don't know what they're doing day to day, until the
next claim comes along. There's no gold standard, and incorporating
one of these other measures would add a lot of information.

Secondly, it is for the most part arbitrary to define good adherence
as Proportion of Days Covered equal or greater to 80%. There's
virtually no research I know of that uses clinical outcomes to
determine where to draw the line on how much you need to take your
medicines. Even those secondary analyses of clinical trial data that I
told you about in the beginning: even they said, let's compare the
over-80% to the under-80% group. At least CMS has artificially made
80% worthwhile by tying some reimbursement it. That's what we're using
in our study, but we haven't yet used any outcome data. There is an
opportunity to incorporate outcomes, such as hospitalization, or even a
surrogate like labs.

Third, we're just looking at statins. There is an opportunity to
expand to other drug classes.

Fourth, we're looking just at statin adherence predicts statin
adherence. What does blood pressure medicine adherence have to say
about statin adherence, or vice versa? You can come up with many of
these possible relationships. Some chronic medications might have
bearing on others; some might not; or only in certain situations. It
turns into a pretty interesting problem.

To sum up, demographic and payment characteristics are not good
predictors of adherence. But those are not the extent of the
information encompassed by claims data. there is valuable signal to be
found in claims data, and people's prior adherence history is one such
signal that can predict future adherence.

[original: 32.5m, 7.16Lpm, 73wpm.]
[current : 2360w, 32.3m]
[target  : 1460-1600w, 20m]

[bring bottle of water!! poss kleenex.]





 LocalWords:  Horwitz NEHI operationalized uber multipage think's LPM meds AUC
 LocalWords:  steiner AUCs tradeoff kleenex WalMart Aetna thru hyperlipidemia
 LocalWords:  Lpm adherers
