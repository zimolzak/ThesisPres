Thanks everyone for coming and for staying for the last presentation
of the day. Up front I would just like to thank my committee members
for their helpful comments through the course of putting this
together. My formal title is "Medication Adherence: how should we
measure it, and can we detect it early?" I will focus mainly on the
early detection.

DEFINITION

But first, some background about medication adherence. I'll use this
definition: "The extent to which patients take medications as
prescribed by their health care providers." Why would you be
interested in such a thing? Who says adherence is good in the first
place?

OUTCOMES

Well, because first of all, poor adherence has been associated with
increased mortality (Horwitz). [**mention healthy adherer] Second,
poor adherence is associated with disease progression in clinical
trials, and with increased disease-related hospitalizations in
real-world populations. Between 30 and 70 % of adverse drug
event-related hospitalizations are attributable to poor adherence.
Furthermore, literature shows that a lot of the increased costs are
due to hospitalizations. So we think that you don't take the medicine,
you get an exacerbation or complication of chronic disease, and you
have a stay in the hospital. It might not even be a bad exacerbation,
but that results in increased costs for you and for the system, and in
indirect costs, such as the things you could be doing while you're not
in the hospital.

COST

A 2009 study from the NEHI estimated 289 billion in what they call
drug-related morbidity in the US. That covers how medications are used
in the ambulatory setting only and it includes adherence problems, as
well as problems with prescribing, administration, and diagnosis,
which result in adverse drug events, interactions, etc.

BONUS

Finally, not too long ago, CMS tied adherence to 3 particular classes
of medications to payment, and one of those classes is the statins.
That informed how we operationalized the definition of adherence.
Payment is actually based on 15-20 different quality measures, but
three of theme are specifically adherence, and they're based on
prescription fills. So even if you don't believe anything about worse
outcomes or costs, if you're a Medicare plan manager, believe that
you're going to make more money if your members are more adherent.

PREVALENT

We know nonadherence is bad. How prevalent is it? It's pretty
prevalent. These are two studies of people who just initiated statins
which show that by 6 months, half of the people have stopped taking
statins. This upper curve is for secondary prevention (if you've just
had a heart attack). You're more likely to continue than are the
people who were just told they have high cholesterol, but it's still
only 50-60% at 6 to 12 months. So stopping medications is a common
occurrence.

MEASURES

Now that we know adherence is important, how do we measure it? There
are several ways, and I already mentioned that Medicare's uses
prescription fills. Second, there are also pill counts. In a trial,
each subject might come back at the end of every month with any unused
pills, to determine how many he or she took. Third, you could ask
patients to keep a diary or retrospectively think back--globally or
quantitatively--how often did you miss, or how well did you do?
Fourth, with some drugs you can order a blood level commercially, or
you can have a specialized research assay that measures levels. Fifth,
you can have [**picture] a device that records each time you open a
bottle. 

Each of these measures has its own pros, cons, and ways they can give
you inaccurate data. there's none that's considered the gold standard.
We use prescription fills. 

For one part of my thesis, which I don't have time to discuss fully, I
reviewed the literature to count how many studies correlate one
measure to another. I would argue that this figure shows that fills
are well studied. They have good correlation with other measures. Just
know that this is not the only way to measure adherence. 

INTERVENTION

Now that we know how to measure adherence, how can we improve it?
There are many trials of adherence interventions, but many are
complex. In one study, for example, an intervention pharmacist was
trained by several other pharmacists, a cardiologist, a geriatrician,
a behavioral scientist, and a cognitive psychologist, and he
intervened over a 9 month period, with effects that dissipated in 3
months (Murray et al., 2007). One systematic review concluded that
"many of the adherence interventions for long-term medications were
exceedingly complex and labor-intensive. It is therefore difficult to
see how they could be carried out in nonresearch settings" (Haynes et
al., 2008). I think when they say that, they forget about one thing
that's simple to do, which is reduce copayment. There was a trial of
that a year and a half ago in the New England Journal, and they found
it improved adherence by 4-6 percentage points, but there was no
significant difference in the incidence rate of the primary outcome,
and small significant differences in the incidence rate of secondary
outcomes. This was an important trial, and it's worth pointing out
that you can do that to a lot of people. There's no logistic problem
with doing that for 10 vs 100 vs 1000. It's not the same as the
pharmacist contacting a thousand people. The point is, we're trying to
do this prediction to target those complex interventions to the people
at highest risk for poor adherence. 

PREVIOUS MODELS

Now that we know why, here's an example of a study that tries to
predict statin adherence from 19 features of the patient, physician,
and drug copayment. The full model had an area under the curve of
0.631. So it didn't work so well. By contrast, a previous study out of
the lab where I'm working showed good model performance by using past
adherence to predict future adherence. However, this study didn't
compare the early detection feature to many other potential features,
and it also selected a cohort who tended to relatively high mean
adherence: higher than that what we expect in the general population.

[stop for questions. want this to be maybe 10 min. Was 13 in original.]

~~~~

RESEARCH

Now I'm going to talk about the main part of the research we did.
[**say that it's about claims]. The dependent variable we defined is
exactly the same way CMS did. It says is adherence greater or less
than this numerical value. It's a binary thing. Then we have a bunch
of independent variables. Sometimes I'll call them predictors or
features. The major predictor we're interested in is adherence for the
first 90 days. That's going into the model as a continuous variable.
The other ones [**probably list them, group of them, etc]. We worked
hard to separate them so we're not using anything beyond the initial 90
days as a predictor or exclusion [**maybe reword]. We excluded anyone
who we don't think is really starting the statin brand new because of
those curves I showed you. They behave differently--at the beginning
there's a big drop. If we get someone who's been on it and monitor
them, they're more likely to keep adhering. It's a different
population because a lot quit early on. That was the main exclusion.
There are some others: people with weird data. [**put figure/table].
We split these 200,000 people into 140,000 training and 70,000 test.
It's a random split. This is logistic regression. I did try other
nonlinear methods but it didn't make a big difference [**omit?]

[**17 min] 7.7 LPM

Some Baseline characteristics of the included population. The median
age is 58. 58 percent men. Most are on simvastatin. After that is
atorvastatin and rosuvastatin. The other ones are minor. Median
adherence for 1-90 is kind of good. The 91-365 is not so good. For the
whole year it's middle of the road. [**say prevalence of <80]. They're
not on a whole lot--just 1-2 other meds. Long tail. There's only 2%
with MI in the last 30 days. So it's mostly a primary prevention
population. [** one or 2 other baseline]

When we looked at bivariate pairwise associations, the big one that
stands out is the early monitoring period. The odds ratio is 18. The
next biggest one is 1.8. The interpretation is if you're the people
with early adherence down by 0.5, then your odds of low adherence in
the later time frame is multiplied by 18. So it's in the intuitive
direction: you do worse at the beginning, and you do worse at the end.

This is the ROC curve for the multivariable model. 

This other guy in his editorial says you can't do anything from claims
data, and there's probably no signal in there. I would agree with what
he says--really what he says is you can't do it from demographic and
comorbidity. I would agree with that but I wouldn't say you can't do
it from claims data. If you use this early monitoring approach. This
early monitoring period is acting as a proxy for a lot of these
unmeasured things that we can't get from claims, like who's working two
jobs or whose work schedule is weird & they have to get up at
different hours & no standard routine. The personal characteristics
are probably a big influence on adherence, is what we think from these
smaller studies where they actually interview and talk to people. None
of that shows up [directly] in insurance claims, but that doesn't mean
that you have no idea about these people. You can wait for 90 days and
monitor their adherence and see how they're doing. So we did better
than the other study. [**should I say I'm not trying to make a straw
man?]

[23 min] 7.3 LPM

Here are the odds ratios of the multivariable model. So things that
are worse for your adherence are on the right side of this graph. The
worst thing is if you have low adherence in the early monitoring
period. This is a log scale. This odds ratio is 20. The next worst one
is 2. That was a drug class one. There are hypotheses for why the drug
class might be worse. [generic versus, but we control for that. Less
potent.] The point of this is not the other covariates. It is
interesting. The interpretation of this one is, age goes up 2 SD, and
the [odds of] adherence gets better. But it's like odds 0.75 or
something. So especially compared to this one, it's not great.

[steiner makes argument that 2 is still not good enough]

This is the really interesting part. This 90 day period was somewhat
arbitrary. We thought 90 days was long enough [from 1st principles].
It worked, but maybe we can make it shorter, or maybe longer gets
better performance. The top curve is people who get 30 day fills of
medications. The Y axis is the AUC, so it's basically how good does
the model predict at whatever time point. If you have only 10 days or
20 of monitoring data, you can't tell anything more than what you
could with 0 days. Interestingly this is pretty close to the AUCs that
the other study was getting. If you wait til 31 you get a big
increase, and if you wait til 40 you get a further increase. You then
start to level off and increase more slowly, for as long as you're
willing to wait. If you wanted to wait 9 months and then predict the
final 3 you could. The point is a tradeoff between early prediction
and striking while the iron is hot; and waiting longer to get a better
fix on their position and what they may do for the rest of the year.
You see a similar pattern for those who get the 90 day fills. They get
a big increase between 90 and 100 days. The timing of the first refill
plays a big part in the discriminatory power of this model.

Compared to other model. Adding early monitoring strategy helps the
power of the model a lot. Editorial says can't predict it from what
people look like or from just drug cost or from what's on the problem
list. I say claims data are limited only if you're trying to predict
before they even start the drug. [only if you disregard the adherence
data that's already there]

Limitations. I showed you with the 5 nodes that there's other ways to
measure adherence apart from fills. The finest resolution I can get is
this 30-day block. I know they filled 30 pills, but then they don't
show up on radar--I don't know what they're doing day to day. There's
other measures. This 80% is for the most part arbitrary. There's maybe
one study that tried to look at this, but it really needs to be
further established how much you need to take your medicines in order
to get clinical benefit. At least CMS has tied some reimbursement to 

[end tape]

a measure. That's what we're using in our study as well. We don't have
outcome data [that we use]. We're just looking at statins. Both of
these are opportunities for future: incorporating outcomes, i.e.
hospitalization, or even a surrogate like labs; and expanding to other
drug classes. Finally, we're looking just at statin adherence predicts
statin adherence. What does blood pressure medicine adherence have to
say about statin adherence, or vice versa? Or you can start to come up
with a whole bunch of things. Some chronic medications might have
bearing on others; some might not; or in certain situations. It turns
into a pretty interesting problem.

[END!!]

[32.5 MINUTES] 7.16 LPM

[bring bottle of water!! poss kleenex.]

[**incorporate]

Q. What would they use it for?

A. Two things. One is insurance plan manager. If people fill these
meds on time, Medicare plan might increase star rating, and then get
an increased bonus payment. Bonus might change. Two is if you're a
clinic or an ACO, you want your people to have fewer complications.
You want to get your hands on fill data, so when someone starts on a
new med you can watch the first refill point, and if they don't within
10 days, you'll want to intervene. There are lots of interventions
and this study doesn't say which to use: letter, reduce copay, reduce
polypharmacy, phone them, mobile electronic reminder. Use what's at
your disposal, I say, but this would alert you that they have a risk
of a problem.

Q. What about auto refill.

A. If you know of a pharmacy that will give me data on that, we could
write a very important paper that no one's written about. I don't have
that data with my claims. I also don't have prescriptions. If it was
prescribed and not filled or prescribed and got at WalMart $4 list,
then it's not a claim on their prescription drug plan.

It's corrupting your data more and more as time goes by but we don't
know to what extent. If we wrote this paper it would Probably spoil
some other research that people are working on. 

[acknowl Aetna?]

** there are people for whom we don't know how to score them.




 LocalWords:  Horwitz NEHI operationalized uber multipage think's LPM meds AUC
 LocalWords:  steiner AUCs tradeoff kleenex WalMart Aetna
