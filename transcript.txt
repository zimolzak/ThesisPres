Thanks everyone for coming and for staying for the last presentation
of the day. Up front I would just like to thank my committee members
for their helpful comments through the course of putting this
together. My formal title is "Medication Adherence: how should we
measure it, and can we detect it early?" 

If you'd like a definition, adherence is the extent to which patients
take medications as prescribed. First I will talk about five simple
facts about adherence that took me a while to realize, and then I will
discuss my research about early detection. 

THE FIRST FACT IS: ADHERENCE IS GOOD.

Poor adherence has been associated with increased mortality. It is
associated with disease progression in clinical trials, and with
increased disease-related hospitalizations in real-world populations.
About half of adverse drug event-related hospitalizations are
attributable to poor adherence, and those hospitalizations cause
increased costs. All of this has been described in a number of
studies. A 2009 study from the NEHI estimated 289 billion annually in
what they call drug-related morbidity in the US. That covers
nonadherence, but also problems with prescribing, administration, and
diagnosis.

Finally, in 2012, CMS tied adherence to 3 particular classes of
medications to payment. Payment is actually based on 15-20 different
quality measures, but three of theme are specifically adherence, and
they're based on prescription fills. So even if you don't believe
anything about worse outcomes or costs, if you're a Medicare plan
manager, believe that adherence is good because it can make you more
money. This CMS definition informed how we operationalized the
definition of adherence.

THE SECOND FACT IS: Nonadherence is common.

These are two studies of people who have been newly prescribed
statins, which are medications that reduce cholesterol. By 6 months,
half have stopped taking statins. This upper curve is for secondary
prevention (if you've just had a heart attack). Your adherence is
better, but not by much.

THIRD FACT: There is No gold standard measure of adherence.

I already mentioned prescription fills as a measure of adherence. A
second measure would be pill counts. In a trial, each subject might
come periodically with any unused pills, to determine how many he or
she took. Third, you could ask patients to keep a diary or
retrospectively think back about how often they took the medication.
Fourth, sometimes you can measure drug levls in blood commercially, or
by research assay. Fifth, you can have [**picture] an electronic
device that records each time you open a pill bottle.

Each of these measures has its own pros and cons. Actually, each is
giving you different information; none of them is considered the gold
standard. In our study, we use prescription fills, per the CMS
definition.

In one chapter of my thesis, which I can't discuss fully, I reviewed
the literature to count how many studies correlate one measure to
another. The width of each edge shows the value of that count, and
brighter colors mean stronger correlation. I would argue that this
figure shows that at least fills are well studied. Just know that they
are not the only way to measure adherence.

FOURTH FACT: adherence Interventions work but can be complex.

There are many trials of adherence interventions, but many are
complex. In one study, an intervention pharmacist was trained by
several other pharmacists, a cardiologist, a geriatrician, a
behavioral scientist, and a cognitive psychologist, and this
well-trained person then delivered an intervention to patients over 9
months, using a tailored protocol. After the intervention period, the
positive effects dissipated in 3 months. One systematic review
concludes, "many of the adherence interventions for long-term
medications were exceedingly complex and labor-intensive. It is
therefore difficult to see how they could be carried out in
non-research settings."

Not everything is complex, though, like this recent trial in the New
England Journal. Here, reduced copayment improved adherence by 4-6
percentage points. There was no significant difference in the primary
outcome, and small differences in secondary outcomes. Reducing
copayment is maybe not so complex as training a small army of
multidisciplinary teams. So not all interventions are exceedingly
complex, but many are.

In any case, this is why we want to predict adherence: to target
expensive interventions to people at highest risk for poor adherence.

FIFTH FACT: Some predictors of adherence don't work so well.

Here's an example of a study that tries to predict statin adherence
from 19 features of the patient, physician, and drug payment levels.
The full model had an area under the curve of 0.63, which means it
didn't work so well. Several papers have stated that we probably can't
predict adherence from someone's appearance, problem list, or
physician or payment characteristics. To quote one review, "adherence
must be measured, not inferred." However, a previous study out of the
lab where I'm working showed good model performance by using past
adherence to predict future adherence. But this paper didn't compare
the early detection feature to many other potential features, and it
also selected a cohort who tended to relatively high mean adherence:
higher than that what we expect in the general population.

This sets up my research, which is meant to build an early detection
model, but do 2 additional things. First, compare the early detection
strategy to the traditional strategy. Second, use the CMS definition
so the model becomes relevant to pay-for-performance.

[stop for questions.]
[original: 13m, 85wpm]
[current : 10.4m, 884w]
[target  : 10m, 850w, 100L]

~~~~

METHODS

Our data source was prescription claims from Aetna, on about 600,000
commercial members, who met criteria for hyperlipidemia.

The major predictor we're interested in is statin adherence for the
first 90 days. That's going into the model as a continuous variable.
This is what I mean when I say the Early Detection Feature: it's this
one number that turns out to add a lot to this model. We then
calculated 15 other predictors including number of non-statin pills,
copayment amounts, features that describe how people obtain their
statins, and whether someone had a heart attack in the 30 days before
statin initiation.

We defined the dependent variable the same way CMS does. It's a binary
condition, specifically whether something called Proportion of Days
Covered is greater or less than 80%, for statins. The dependent
variable starts at day 91, so nothing beyond the early monitoring
period is used as a predictor.

We excluded anyone who we don't think is really newly initiating the
statins, because we know populations behave differently when starting
versus maintaining medications. Then there are some less common
exclusion criteria. We're left with 210,000 people. We randomly chose
a 2/3 training and a 1/3 test set. We trained logistic regression and
applied the model to the test set.

[original: 17m, 7.7Lpm, 79wpm]

RESULTS

In our cohort, here are some simple characteristics. They are not on
very many other medications, and few have had a recent heart attack.
Nonadherence is common, similar to levels seen in other studies.

This is the ROC curve for our multivariable model. Area under the
curve is 0.8, so we think this is a good model. Remember the
commentary about the study with 0.63 AUC. You can't make accurate
predictions from demographic and comorbidity data. I would still agree
with that. But if you use this early monitoring period, it probably
acts as a proxy for personal characteristics that we can't get from
claims, like who forgets their meds because they're working two jobs.
Personal characteristics are probably a big influence on adherence.

[original: 23m, 7.3Lpm, 74wpm]

Here are the odds ratios. Associates of poor adherence are on the
right. The strongest predictor is low adherence in the early
monitoring period, with an odds ratio of 25. The interpretation is: if
your early adherence is 2 standard deviations lower, then your odds of
low adherence in future are multiplied by 20. This is the intuitive
direction: lower in past predicts lower in future. The point is these
runners up, but how far the early detection feature stands out.

Finally, this is the interesting part. The 90 day early detection
period made clinical sense, but maybe it shouldn't be 90. We plotted
model performance on the Y axis versus length of the early monitoring
period on the X axis. The top curve is the major cohort who get 30 day
fills of medications, and the bottom curve is a small cohort who get
90 day fills. For the top curve, if you have 0 to 30 days of
monitoring data, you get a weak model, with an AUC around 0.6, not far
from the study I showed you. If you wait for 31 days of data, you get
a a better model, and if you wait til 40 you get even better. There is
a tradeoff between an early, less accurate prediction; and a later
more accurate one. You see a similar pattern for those who get the 90
day fills.

[**table from poster]

DISCUSSION

Who would use this? One is insurance plan manager. If people fill
these meds on time, Medicare plan might increase star rating, and then
get an increased bonus payment. Two is if you're a clinic or an ACO,
you want your people to have fewer complications. You want to get your
hands on fill data, so when someone starts on a new med you can watch
the first refill point, and if they don't within 10 days, you'll want
to intervene.

Now I want to discuss opportunities for future research. At the
beginning, I showed you that there's other ways to measure adherence
apart from fills. Prescription claims are not the same as
quote-unquote true adherence. With a claim, I know they filled 30
pills, but then I don't know what they're doing day to day, until the
next claim comes along. There's no gold standard, and incorporating
one of these other measures would add a lot of information.

Secondly, it is for the most part arbitrary to define good adherence
as Proportion of Days Covered equal or greater to 80%. There's
virtually no research I know of that uses clinical outcomes to
determine where to draw the line on how much you need to take your
medicines. Even those secondary analyses of clinical trial data that I
told you about in the beginning: even they said, let's compare the
over-80% to the under-80% group. At least CMS has artificially made
80% worthwhile by tying some reimbursement it. That's what we're using
in our study, but we haven't yet used any outcome data. There is an
opportunity to incorporate outcomes, such as hospitalization, or even a
surrogate like labs.

Third, we're just looking at statins. There is an opportunity to
expand to other drug classes.

Fourth, we're looking just at statin adherence predicts statin
adherence. What does blood pressure medicine adherence have to say
about statin adherence, or vice versa? You can come up with many of
these possible relationships. Some chronic medications might have
bearing on others; some might not; or only in certain situations. It
turns into a pretty interesting problem.

To sum up, demographic and payment characteristics are not good
predictors of adherence. But those are not the extent of the
information encompassed by claims data. there is valuable signal to be
found in claims data, and people's prior adherence history is one such
signal that can predict future adherence.

[original: 32.5m, 7.16Lpm, 73wpm.]
[current : 29m, 2141w]
[target  : 1460-1600w, 20m]

[bring bottle of water!! poss kleenex. Put on the side: my paper, my
definition. steiner paper.]





 LocalWords:  Horwitz NEHI operationalized uber multipage think's LPM meds AUC
 LocalWords:  steiner AUCs tradeoff kleenex WalMart Aetna thru hyperlipidemia
 LocalWords:  Lpm adherers
