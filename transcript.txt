Thanks everyone for coming and for staying for the last presentation.
I would like to thank my committee for their helpful comments through
the course of putting this together. My thesis is called "Medication
Adherence: how should we measure it, and can we detect it early?"

If you'd like a definition, adherence is the extent to which patients
take medications as prescribed. First I will talk about five
background facts about adherence, and then I'll discuss my research
about early detection.

THE FIRST FACT IS: ADHERENCE IS GOOD.

Poor adherence is associated with increased mortality and disease
progression in clinical trials, and with increased disease-related
hospitalizations in observational studies. Half of adverse drug
event-related hospitalizations are attributable to poor adherence, and
those hospitalizations cause increased costs. One study estimates 289
billion dollars annually in drug-related morbidity in the US. That
covers nonadherence, but also problems with prescribing,
administration, and diagnosis.

Secondly, the Centers for Medicare and Medicaid Services has tied
adherence for certain drugs to Medicare bonus payments. CMS measures
adherence using prescription fills. Even if you don't believe the
worse outcomes or costs, if you're a Medicare plan manager, believe
that adherence is good because it can make you more money. This CMS
definition informed how we operationalized the definition of
adherence.

THE SECOND FACT IS: Nonadherence is common.

These are two studies of people who have been newly prescribed
statins, which are medications that reduce cholesterol. By 6 months,
half have stopped taking statins. This upper curve is for secondary
prevention (if you've just had a heart attack). Your adherence is
better, but not by much.

THIRD FACT: There is No gold standard measure of adherence.

I already mentioned that Medicare uses prescription fills. A second
measure would be pill counts. In a trial, each subject might come in
periodically with any unused pills, to determine how many he or she
took. Third, you could ask patients to keep a diary or retrospectively
report about how often they took the medication. Fourth, you can
measure drug levels in blood. Fifth, a specialized electronic device
can record each time you open a pill bottle. Each of these measures
has its own pros and cons. Actually, each is giving you different
information, so none is considered the gold standard. In our study, we
use prescription fills, per the CMS definition.

In one chapter of my thesis, which I can't discuss fully, I reviewed
the literature to count how many studies correlate one measure to
another. The width of each edge shows the value of that count, and
brighter colors mean stronger correlation. I would argue that this
figure shows that at least fills are well studied. Just know that they
are not the only way to measure adherence.

FOURTH FACT: adherence Interventions work but can be complex.

In one study, for example, an intervention pharmacist was trained by
several other pharmacists, a cardiologist, a geriatrician, a
behavioral scientist, and a cognitive psychologist, and this
expertly-trained pharmacist then delivered an intervention to patients
over 9 months, using a tailored protocol. After the intervention
period, the positive effects dissipated in 3 months. One systematic
review concludes, "many of the adherence interventions for long-term
medications were exceedingly complex and labor-intensive. It is
therefore difficult to see how they could be carried out in
non-research settings."

A minority of intervention studies are simple. In this one, reduced
copayment improved adherence by 4-6 percentage points. There was no
significant difference in the primary outcome, but small differences
in secondary outcomes. Reducing copayment is arguably simple compared
to training a small army of multidisciplinary teams.

In any case, these interventions illustrate why we want to predict
adherence. We think we can deliver interventions only to some: who
should be at highest risk.

FIFTH FACT: Some predictors of adherence don't work so well.

This study's goal was to predict statin adherence from 19 features of
the patient, physician, and payment amounts. The full model had an
area under the curve of 0.63, which means it didn't work so well.
Several papers have stated that we probably can't predict adherence
from someone's appearance, problem list, or physician or payment
characteristics. To quote one review, "adherence must be measured, not
inferred." However, a previous study out of the lab where I'm working
showed good model performance by using past adherence to predict
future adherence. But this paper didn't compare the early detection
feature to many other potential features, and it also selected a
cohort who tended to relatively high mean adherence.

This sets up my research, which is meant to build an early detection
model, but do 2 additional things. First, compare the early detection
feature to traditional features. Second, use the CMS definition so the
model becomes relevant to pay-for-performance.

Are there any questions before I move on to research?







All right. Our data source was prescription claims from Aetna, on
about 600,000 commercial members, who met criteria for hyperlipidemia.

The major predictor of interest is statin adherence for the first 90
days. That's going into the model as a continuous variable. When I say
Early Detection Feature, I mean this one number that turns out to add
a lot to this model. In addition to it, we calculated 15 traditional
predictors including number of non-statin pills, copayment amounts,
features describing how people obtain their statins, and whether
someone had a heart attack in the 30 days before statin initiation.

We defined the dependent variable per CMS. It's a binary condition,
specifically whether something called Proportion of Days Covered is
greater or less than 80%, for statins. The dependent variable starts
at day 91, so no information from the dependent variable is in the early monitoring period.

We excluded anyone who we don't think is really newly initiating the
statins, because we know populations behave differently when starting
versus maintaining medications. Then there are some less common
exclusion criteria. We're left with 210,000 people. We randomly chose
a 2/3 training and a 1/3 test set. We trained logistic regression and
applied the model to the test set.

In our cohort, here are some simple characteristics. They are not on
very many other medications, and few have had a recent heart attack.
Nonadherence is common, similar to levels seen in other studies.

This is the ROC curve for our multivariable model. Area under the
curve is 0.8, so we think this is a good model. Remember the
commentary about the study with 0.63 AUC. The editorial said you can't
make accurate predictions from demographic and comorbidity data. I
would still agree with that. But our early monitoring period probably
acts as a proxy for personal characteristics that we can't get from
claims: for example: who forgets their meds because they're working two jobs.
Personal characteristics are probably a big influence on adherence.

Here are the odds ratios. Associates of poor adherence are on the
right. The strongest predictor is low adherence in the early
monitoring period, with an odds ratio of 25. The interpretation is: if
your early adherence is 2 standard deviations lower, then your odds of
low adherence in future are multiplied by 20. This is the intuitive
direction: lower in past predicts lower in future. The point is these
runners up, but how far the early detection feature stands out.

Finally, this is the interesting part. The 90 day early detection
period made clinical sense, but maybe it shouldn't be 90. We plotted
model performance on the Y axis versus length of the early monitoring
period on the X axis. The top curve is the major cohort who get 30 day
fills of medications, and the bottom curve is a small cohort who get
90 day fills. For the top curve, if you have 0 to 30 days of
monitoring data, you get a weak model, with an AUC around 0.6, not far
from the study I showed you. If you wait for 31 days of data, you get
a a better model, and if you wait til 40 you get even better. There is
a trade-off between an early, less accurate prediction; and a later
more accurate one. You see a similar pattern for those who get the 90
day fills.

[**table from poster]. At 40 days we see __ specificity, __
sensitivity.

Who could use this model? One person is an insurance plan manager.
Find people filling a medicine for the first time, monitor their
refills, intervene early, and improve your pay-for-performance. A
second example is simply a clinic or an ACO: intervene early and
improve your disease complication rate.

Now I want to discuss opportunities for future research. At the
beginning, I showed you other ways to measure adherence apart from
fills. With fills, I can't see what people are doing day to day. So
you can see that one of these other measures would add a lot of
information.

Secondly, it's arbitrary to define good adherence as Proportion of
Days Covered equal or greater than 80%. I haven't seen a paper using
clinical outcomes to determine where to draw the line on how much you
need to take your medicines. At least CMS has artificially made 80%
worthwhile by tying reimbursement to it. There is an opportunity to
incorporate outcomes, such as hospitalization, or even a surrogate
like labs.

Third, we're looking just at statin adherence predicts statin
adherence. What does blood pressure medicine adherence have to say
about statin adherence, or vice versa? You can come up with many of
these possible relationships. Some chronic medications might have
bearing on others; some might not; or only in certain situations. It
turns into a pretty interesting problem.

To sum up, demographic and payment characteristics are not good
predictors of adherence, but early adherence is one useful predictor
to be found in claims data. Medication adherence is an important
problem, and there are many important questions that clinicians and
adherence researchers will be able to answer about it in the near
future.
