\documentclass[12pt]{report}
\usepackage{speech} % may or may not use xelatex
\begin{document}

\begin{large}

Thanks everyone for coming and staying for the last presentation. And
thanks my committee for all their support through the course of this
research. My thesis is called ``Medication Adherence: how should we
measure it, and can we detect it early?''

If you'd like a definition, adherence is the extent to which patients
take medications as prescribed. First I'll cover five background facts
about adherence, and then I'll discuss my research about early
detection.

THE FIRST FACT IS: ADHERENCE IS GOOD.

Poor adherence is associated with increased mortality and disease
progression in clinical trials, and with increased disease-related
hospitalizations in observational studies. Between 30 and 70 \% of
adverse drug event-related hospitalizations are attributable to poor
adherence, and these hospitalizations are a major cause of increased
costs. One study estimates 289 billion dollars annually in
drug-related morbidity in the US. That includes nonadherence, but also
problems with prescribing, administration, and diagnosis.

So we think that you don't take the medicine, you get an exacerbation
or complication of chronic disease, and you have a stay in the
hospital. It might not even be a bad exacerbation, but that results in
increased costs for you and for the system. %wordy

Furthermore, the Centers for Medicare and Medicaid Services has tied
adherence for certain drugs to Medicare bonus payments. 

Payment is actually based on 15-20 different quality measures, but
three of them are specifically adherence. %wordy

CMS measures adherence using prescription fills. Even if you don't
believe the worse outcomes or costs, if you're a Medicare plan
manager, believe that adherence is good because it can get you more
reimbursement. This CMS definition informed how we operationalized the
definition of adherence.

SECOND FACT: Nonadherence is common.

These are two studies of people who have been newly prescribed
statins, which are medications that reduce cholesterol. By 6 months,
half have stopped taking statins. This upper curve is for those who
have just recently had a heart attack. Nonadherence is still common,
but less so.

THIRD FACT: There is No gold standard measure of adherence.

I mentioned that Medicare uses prescription fills as its measure of
adherence. A second measure would be pill counts. In a trial, each
subject might come in periodically with any unused pills, to determine
how many he or she took. Third, patients could keep a diary or recall
how often they took their medication. Fourth, you can assay drug
levels in blood. Fifth, a specialized electronic device can record
each time someone opens a pill bottle. Each measure has its own pros
and cons. Actually, each is giving you different information, so none
is the gold standard. In our study, we use prescription fills, per the
CMS definition.

In one chapter of my thesis, which I can't discuss in detail, I
reviewed the literature to count the studies correlating one measure
to another. The width of each edge shows the count of studies, and
brighter colors mean stronger correlation. I would argue that this
figure shows that at least fills are well studied. Just know that they
are not the only way to measure adherence.

FOURTH FACT: adherence Interventions work but can be complex.

In one study, an intervention pharmacist was trained by several other
pharmacists, a cardiologist, a geriatrician, a behavioral scientist,
and a cognitive psychologist, and then this expertly-trained
pharmacist delivered an intervention to patients over 9 months, using
a tailored protocol. After the intervention period was over, the
positive effects dissipated in 3 months. One systematic review
concludes, ``many of the adherence interventions for long-term
medications were exceedingly complex and labor-intensive. It is
therefore difficult to see how they could be carried out in
non-research settings.''

A few interventions are simpler. In this one from 2011, reduced copayment
improved adherence by 4-6 percentage points. There was no significant
difference in the primary outcome, but small differences in secondary
outcomes. Reducing copayment is arguably simple compared to training a
small army of multidisciplinary teams.

In any case, these interventions illustrate why we want to predict
adherence. We think the resource-intensive intervention is not for
everyone---some people will do well on their own.

FIFTH FACT: Some predictors of adherence don't work.

One study tried to predict statin adherence from 19 features of the
patient, physician, and payment amounts. The resulting model had an
area under the curve of 0.63, which means it didn't work so well.
Several papers have stated that we probably can't predict adherence
from someone's appearance, problem list, or physician or payment
characteristics. To put it briefly, ``adherence must be measured, not
inferred.'' However, a study from my lab showed good model performance
by using past prescription claims to predict future prescription
claims. But this study didn't compare the early detection feature to
many other potential features, and it also selected a cohort who
tended to relatively high mean adherence.

This sets up my research, which is meant to build an early detection
model, but do 2 additional things. First, compare the early detection
feature to traditional features. Second, use the CMS definition so the
model becomes relevant to pay-for-performance.

Are there any questions before I move on to research?







All right. Our data source was prescription claims from Aetna, on
600,000 commercial members, who met criteria for hyperlipidemia.

The major predictor of interest is statin adherence 90 days after
prescribing, as a continuous variable. When I say Early Detection
Feature, I mean this one number that turns out to add a lot to this
model. In addition to it, we calculated 15 traditional predictors
including number of non-statin pills, copayment, features describing
how people obtain medications, and whether someone had a heart attack
in the 30 days before statin initiation.

We defined the dependent variable per CMS. It is binary statin
adherence: specifically whether something called Proportion of Days
Covered is greater or less than 80\%, for statins. It covers days
91-365, so no information from the dependent variable is in the early
monitoring period.

We excluded a few conditions: mainly anyone who we don't think is
really newly initiating the statins, because we know populations
behave differently when starting versus maintaining medications. We're
left with 210,000 people. We trained logistic regression on a random
2/3 training set and applied the model to a 1/3 test set.

Here are simple characteristics of our cohort. They are not on many
medications, and few have had a recent heart attack. Nonadherence is
common, as seen in other studies.

This is the ROC curve for our multivariable model. Area under the
curve is 0.8, so we think this is a good model. Remember the
commentary we heard before: that you can't make accurate predictions
from demographic and comorbidity data. I would still agree with that.
But our early monitoring period probably acts as a proxy for personal
characteristics that we can't get from claims: for example: who
forgets their meds because they're working two jobs. Personal
characteristics like these are probably a big influence on adherence.

Here are multivariable odds ratios. Associates of poor adherence fall
on the right, and associates of good adherence are on the left. The
strongest predictor is low adherence in the early monitoring period,
with an odds ratio of 25. The interpretation is: if early adherence is
2 standard deviations lower, the odds of poor adherence in future are
multiplied by 25. This is the intuitive direction: lower in past
predicts lower in future. This is a log scale. The point is not these
runners up, but how much the early detection feature stands out. One
review article makes the argument that an odds ratio of 2 is still not
very good for predicting something common like adherence.

Finally, this is the really interesting part. The 90 day early
detection period made clinical sense, but maybe it shouldn't be 90. We
plotted model performance on the Y axis versus duration of the early
monitoring period on the X axis. The top curve is the major cohort who
get 30 day fills of medications, and the bottom curve is a small
cohort who get 90 day fills. For the top curve, if you have 0 to 30
days of monitoring data, you get a weak model, with an AUC around 0.6,
not far from the study I showed you. If you wait for 31 days of data,
you get a a better model, and if you wait til 40 you get even better.
Then you increase more slowly, for as long as you're willing to wait.
There is a trade-off between an early, less accurate prediction; and a
later more accurate one. You see a similar pattern for those who get
the 90 day fills.

[**table from poster]. At 40 days we see -- specificity, --
sensitivity.

Who could use this model? Firstly, insurance plan managers. Find
people filling a medicine for the first time, monitor their refills,
intervene early, and improve your pay-for-performance. Secondly,
clinics or ACOs could use this: similarly intervene early but with the
goal of improving their disease complication rates.

Now I want to discuss opportunities for future research. Remember
there are ways to measure adherence other than fills. With fills, I
can't see what people are doing day to day. So using an additional one
of these measures would add a lot of information.

Secondly, it's arbitrary to define good adherence as Proportion of
Days Covered equal or greater than 80\%. I haven't seen a paper using
clinical outcomes to determine where to draw this line.

\end{large}

The question is not ``do you need to take your medicines?'' It's
``exactly \emph{how much} do you need to take your medicines?''

\begin{large}

At least CMS has artificially made 80\% meaningful by tying
reimbursement to it. There is an opportunity to incorporate outcomes,
such as hospitalization, or even surrogate outcomes like cholesterol.

Third, we're looking just at statin adherence predicting statin
adherence. What does antidepressant adherence have to say about statin
adherence, or vice versa? You can imagine an entire network of
possible correlations. Some chronic medications might have bearing on
others; some might not; or only in certain situations. It becomes a
very interesting question.

To sum up, demographic and payment characteristics are not good
predictors of statin prescription filling, but early statin adherence
is one useful predictor found in claims data. Medication adherence is
an important problem, and there are many important questions that
clinicians and adherence researchers will be able to answer about it
in the near future.

%Was 1557 wd, 15 min? 12 pp.
%Now 1739 wd, 17 min? 13 pp.

\end{large}

\end{document}

% LocalWords:  operationalized
